{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85cb6b48",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n",
    "RAG: models which combine pre-trained parametric and non-parametric memory for language generation\n",
    "\n",
    "- **Parametric knowledge**: Learned during training that is implicitly stored in the neural network's weights.\n",
    "- **Non-parametric knowledge**: Stored in an external knowledge source, such as a vector database.\n",
    "\n",
    "For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3d37d3",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "- langchain for orchestration\n",
    "- openai for the embedding model and LLM\n",
    "- weaviate-client for the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418569ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2329736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/hwchase17/chroma-langchain/88bd99222d46f763957c2873e48bbba2f3e4b36a/state_of_the_union.txt\"\n",
    "res = requests.get(url)\n",
    "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
    "    f.write(res.text)\n",
    "\n",
    "loader = TextLoader('./state_of_the_union.txt')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "client = weaviate.connect_to_local(skip_init_checks=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d96c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "448dd340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8944a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cohere_api_key = os.getenv(\"COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "741bbd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naina\\anaconda3\\Lib\\site-packages\\weaviate\\collections\\classes\\config.py:1975: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  for cls_field in self.model_fields:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.sync.Collection at 0x2608eb655e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weaviate.classes.config as wvc\n",
    "client.collections.delete(\"RAGChunks\")\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"RAGChunks\",\n",
    "    description=\"Chunks with externally-generated embeddings\",\n",
    "    vectorizer_config=wvc.Configure.Vectorizer.none(),\n",
    "    properties=[\n",
    "        wvc.Property(name=\"text\", data_type=wvc.DataType.TEXT),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ce830e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e902ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "307204f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade langchain-weaviate weaviate-client>=4.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31360cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_weaviate import WeaviateVectorStore\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "vectorstore = WeaviateVectorStore(\n",
    "    client=client,\n",
    "    index_name=\"RAGChunks\",\n",
    "    text_key=\"text\",\n",
    "    embedding=embedding,  \n",
    "    attributes=[\"source\"]  # Include metadata fields\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d17f8ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.add_documents(documents=chunks)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ebbcdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\\n\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1f38190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"meta-llama/llama-4-scout-17b-16e-instruct\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70487bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e1c2e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context describes Ukrainians as a \"proud\" people who have shown they will not tolerate anyone trying to take their country backwards, and mentions their fight for freedom. It also highlights their courage in fighting back against Russian aggression. The speaker expresses support for the Ukrainians, stating that the US is providing over $1 Billion in direct assistance.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did they say about Ukrainians?\"\n",
    "rag_chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
